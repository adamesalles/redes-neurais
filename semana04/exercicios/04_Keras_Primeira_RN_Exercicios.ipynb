{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "## Usando Keras para Construir e Treinar Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "Neste exercício usaremos uma rede neural para prever diabetes usando o Dataset de Diabetes Pima. Começaremos treinando uma Random Forest para obter uma linha de base de desempenho. Em seguida, usaremos o pacote Keras para construir e treinar rapidamente uma rede neural e comparar o desempenho. Veremos como diferentes estruturas de rede afetam o desempenho, o tempo de treinamento e o nível de overfitting (ou underfitting).\n",
    "\n",
    "## Dataset de Diabetes Pima da UCI\n",
    "\n",
    "* Repositório ML da UCI (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Atributos: (todos com valores numéricos)\n",
    "   1. Número de vezes grávida\n",
    "   2. Concentração de glicose plasmática 2 horas após teste oral de tolerância à glicose\n",
    "   3. Pressão arterial diastólica (mm Hg)\n",
    "   4. Espessura da dobra cutânea do tríceps (mm)\n",
    "   5. Insulina sérica de 2 horas (mu U/ml)\n",
    "   6. Índice de massa corporal (peso em kg/(altura em m)^2)\n",
    "   7. Função de pedigree da diabetes\n",
    "   8. Idade (anos)\n",
    "   9. Variável de classe (0 ou 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "O Dataset de Diabetes Pima da UCI que possui 8 preditores numéricos e um resultado binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminares\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar objetos do Keras para Deep Learning\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carregar o conjunto de dados (Acesso à Internet necessário)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/refs/heads/master/diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(url)\n",
    "diabetes_df.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dar uma olhada nos dados -- se houver muitos \"NaN\" você pode ter problemas de conectividade com a internet\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em Treinamento e Teste (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "Acima, vemos que cerca de 35% dos pacientes neste dataset têm diabetes, enquanto 65% não têm. Isso significa que podemos obter uma precisão de 65% sem nenhum modelo - apenas declarando que ninguém tem diabetes. Calcularemos a pontuação ROC-AUC para avaliar o desempenho do nosso modelo, e também observaremos a precisão para ver se melhoramos a precisão de 65%.\n",
    "## Exercício: Obtenha um desempenho de linha de base usando Random Forest\n",
    "Para começar e obter uma linha de base para o desempenho do classificador:\n",
    "1. Treine um modelo Random Forest com 200 árvores nos dados de treinamento.\n",
    "2. Calcule a precisão e o roc_auc_score das predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treinar o Modelo RF\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de teste - tanto previsões \"definitivas\" quanto os scores (porcentagem de árvores votando sim)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Construir uma Rede Neural de Camada Oculta Única\n",
    "\n",
    "Usaremos o modelo Sequential para construir rapidamente uma rede neural. Nossa primeira rede será uma rede de camada única. Temos 8 variáveis, então definimos o formato de entrada como 8. Vamos começar tendo uma única camada oculta com 12 nós."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Primeiro vamos normalizar os dados\n",
    "## Isso auxilia o treinamento de redes neurais fornecendo estabilidade numérica\n",
    "## Random Forest não precisa disso pois encontra apenas uma divisão, ao contrário de realizar multiplicações de matrizes\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o Modelo \n",
    "# Tamanho de entrada é 8-dimensional\n",
    "# 1 camada oculta, 12 nós ocultos, ativação sigmoid\n",
    "# Camada final tem apenas um nó com ativação sigmoid (padrão para classificação binária)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta é uma ferramenta útil para visualizar o modelo que você criou e contar os parâmetros\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Pergunta de compreensão:\n",
    "Por que temos 121 parâmetros? Isso faz sentido?\n",
    "\n",
    "\n",
    "Vamos ajustar nosso modelo por 200 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar(Treinar) o Modelo\n",
    "\n",
    "# Compilar o modelo com Otimizador, Função de Perda e Métricas\n",
    "# Roc-Auc ainda não está disponível no Keras como uma métrica pronta para uso, então vamos pular isso aqui.\n",
    "\n",
    "model_1.compile(SGD(learning_rate = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# a função fit retorna o histórico de execução. \n",
    "# É muito conveniente, pois contém informações sobre o ajuste do modelo, iterações etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Como fizemos para o Random Forest, geramos dois tipos de previsões\n",
    "# Uma é uma decisão definitiva, a outra é um score probabilístico.\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos verificar as saídas para ter uma noção de como as APIs do keras funcionam.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir performance do modelo e plotar a curva roc\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "Pode haver alguma variação nos números exatos devido à aleatoriedade, mas você deve obter resultados na mesma faixa da Random Forest - entre 75% e 85% de precisão, entre 0,8 e 0,9 para AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "Vamos observar o objeto `run_hist_1` que foi criado, especificamente seu atributo `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "Vamos plotar a perda de treinamento e a perda de validação ao longo das diferentes épocas e ver como fica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "Parece que as perdas ainda estão diminuindo tanto no conjunto de treinamento quanto no conjunto de validação. Isso sugere que o modelo pode se beneficiar de mais treinamento. Vamos treinar o modelo um pouco mais e ver o que acontece. Observe que ele continuará de onde parou. Treine por mais 1000 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note que quando chamamos \"fit\" novamente, ele continua de onde parou\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "Observe que este gráfico começa onde o outro parou. Embora a perda de treinamento ainda esteja diminuindo, parece que a perda de validação se estabilizou (ou até piorou!). Isso sugere que nossa rede não se beneficiará de mais treinamento. Qual é o número apropriado de épocas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "Agora é sua vez. Faça o seguinte nas células abaixo:\n",
    "- Construa um modelo com duas camadas ocultas, cada uma com 6 nós\n",
    "- Use a função de ativação \"relu\" para as camadas ocultas, e \"sigmoid\" para a camada final\n",
    "- Use uma taxa de aprendizado de 0,003 e treine por 1500 épocas\n",
    "- Faça um gráfico da trajetória das funções de perda, precisão tanto no conjunto de treino quanto no de teste\n",
    "- Plote a curva ROC para as predições\n",
    "\n",
    "Experimente com diferentes taxas de aprendizado, números de épocas e estruturas de rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite seu código aqui com as camadas 1,2 tendo ativação relu e camada 3 com ativação sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite seu código aqui para plotar a perda, acurácia e curva ROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
