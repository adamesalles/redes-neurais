{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning usando dados MNIST\n",
    "Para ilustrar o poder e o conceito de transfer learning, treinaremos uma CNN apenas nos dígitos 5,6,7,8,9. Em seguida, treinaremos apenas a(s) última(s) camada(s) da rede nos dígitos 0,1,2,3,4 e veremos quão bem as características aprendidas nos dígitos 5-9 ajudam na classificação dos dígitos 0-4.\n",
    "\n",
    "Adaptado do Exemplo do Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminares\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Compatibilidade Python 2/3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar objetos do Keras para Deep Learning\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usado para ajudar algumas das funções de tempo\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir alguns parâmetros\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir mais alguns parâmetros\n",
    "img_rows, img_cols = 28, 28\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Isso apenas lida com alguma variabilidade na forma como os dados de entrada são carregados\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para simplificar as coisas, escreva uma função para incluir todas as etapas de treinamento\n",
    "## Como entrada, a função recebe um modelo, conjunto de treinamento, conjunto de teste e o número de classes\n",
    "## Dentro do objeto modelo estará o estado sobre quais camadas estamos congelando e quais estamos treinando\n",
    "\n",
    "def train_model(model, train, test, num_classes):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('formato de x_train:', x_train.shape)\n",
    "    print(x_train.shape[0], 'amostras de treino')\n",
    "    print(x_test.shape[0], 'amostras de teste')\n",
    "\n",
    "    # converter vetores de classe em matrizes de classe binárias\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Tempo de treinamento: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Pontuação no teste:', score[0])\n",
    "    print('Precisão no teste:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os dados, embaralhados e divididos entre conjuntos de treino e teste\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# criar dois conjuntos de dados: um com dígitos abaixo de 5 e outro com 5 e acima\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as camadas de \"características\". Essas são as camadas iniciais que esperamos que \"transfiram\"\n",
    "# para um novo problema. Congelaremos essas camadas durante o processo de fine-tuning\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as camadas de \"classificação\". Essas são as camadas posteriores que predizem as classes específicas a partir das características\n",
    "# aprendidas pelas camadas de características. Esta é a parte do modelo que precisa ser re-treinada para um novo problema\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos nosso modelo combinando os dois conjuntos de camadas da seguinte forma\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dar uma olhada\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, vamos treinar nosso modelo nos dígitos 5,6,7,8,9\n",
    "\n",
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congelando Camadas\n",
    "O Keras permite que as camadas sejam \"congeladas\" durante o processo de treinamento. Ou seja, algumas camadas teriam seus pesos atualizados durante o processo de treinamento, enquanto outras não. Esta é uma parte central do transfer learning, a capacidade de treinar apenas a última ou várias camadas.\n",
    "\n",
    "Observe também que muito do tempo de treinamento é gasto \"retropropagando\" os gradientes de volta para a primeira camada. Portanto, se precisarmos apenas calcular os gradientes de volta a um pequeno número de camadas, o tempo de treinamento é muito mais rápido por iteração. Isso além das economias obtidas por poder treinar em um conjunto de dados menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar apenas as camadas de características\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe abaixo as diferenças entre o número de *parâmetros totais*, *parâmetros treináveis* e *parâmetros não-treináveis*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que após uma única época, já estamos alcançando resultados na classificação de 0-4 que são comparáveis àqueles alcançados em 5-9 após 5 épocas completas. Isso apesar do fato de que estamos apenas \"ajustando\" a última camada da rede, e todas as camadas iniciais nunca viram como os dígitos 0-4 se parecem.\n",
    "\n",
    "Além disso, observe que mesmo que quase todos (590K/600K) dos *parâmetros* fossem treináveis, o tempo de treinamento por época ainda foi muito reduzido. Isso ocorre porque a parte não congelada da rede era muito superficial, tornando a retropropagação mais rápida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "### Para fazer:\n",
    "- Agora escreva código para reverter este processo de treinamento. Ou seja, você treinará nos dígitos 0-4, e então fará fine-tune apenas das últimas camadas nos dígitos 5-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
