\documentclass[a4paper,12pt]{article}

% Pacotes essenciais
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{tikz}
\usetikzlibrary{positioning, arrows.meta, shapes}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{float}
\usepackage{minted}
\usepackage{pgfplots}
\usepackage[minted, most]{tcolorbox}
\usepackage{algorithm}
\usepackage{algorithmic}

% Configuração de cabeçalho e rodapé
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Curso de Redes Neurais - Semana 6}
\fancyhead[R]{24 de setembro de 2025}
\fancyfoot[C]{\thepage}

% Configuração de links
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue
}

% Configurações do TikZ
\usetikzlibrary{arrows.meta, shapes, positioning, calc}
\pgfplotsset{compat=1.17}

% Definição de cores
\definecolor{nes_dark_orange}{RGB}{255,140,0}
\definecolor{nes_dark_purple}{RGB}{128,0,128}
\definecolor{highlight}{RGB}{255,165,0}

% Comandos personalizados
\newcommand{\highlight}[1]{{\color{nes_dark_orange}\textbf{#1}}}
\newcommand{\grad}[2]{\frac{\partial #1}{\partial #2}}

% Ambientes personalizados
\tcbuselibrary{theorems}
\newtcbtheorem[number within=section]{definicao}{Definição}{
    colback=blue!5!white,
    colframe=blue!75!black,
    fonttitle=\bfseries
}{def}

\newtcbtheorem[number within=section]{teorema}{Teorema}{
    colback=green!5!white,
    colframe=green!75!black,
    fonttitle=\bfseries
}{teo}

\newtcbtheorem[number within=section]{exemplo}{Exemplo}{
    colback=orange!5!white,
    colframe=orange!75!black,
    fonttitle=\bfseries
}{ex}

\newtcbtheorem[number within=section]{observacao}{Observação}{
    colback=yellow!5!white,
    colframe=yellow!75!black,
    fonttitle=\bfseries
}{obs}

\newtcbtheorem[number within=section]{algoritmo}{Algoritmo}{
    colback=purple!5!white,
    colframe=purple!75!black,
    fonttitle=\bfseries
}{alg}

% Informações do documento
\title{Notas de Aula - Semana 6 \\
       \large Introdução às Redes Neurais Convolucionais\\
       \itshape Curso de Redes Neurais}
\author{Eduardo Adame}
\date{24 de setembro de 2025}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introdução}

As Redes Neurais Convolucionais (CNNs) representam um dos avanços mais significativos em aprendizado de máquina, especialmente para processamento de imagens. Enquanto as redes neurais tradicionais (Multi-Layer Perceptrons - MLPs) tratam todos os inputs de forma independente, as CNNs foram projetadas especificamente para explorar a estrutura espacial presente em dados visuais.

Este documento explora a motivação por trás das CNNs, seus componentes fundamentais, e como elas superam as limitações das MLPs para tarefas de visão computacional. Veremos que as CNNs são, essencialmente, MLPs especializadas que incorporam conhecimento sobre a natureza hierárquica e local dos padrões visuais.

\section{Motivação: As Limitações das MLPs para Imagens}

\subsection{O Problema da Explosão de Parâmetros}

Quando aplicamos MLPs diretamente a imagens, enfrentamos imediatamente um problema de escala. Considere uma imagem colorida modesta de 200×200 pixels com três canais de cor (RGB). Isso resulta em 200 × 200 × 3 = 120.000 valores de entrada. Em uma MLP totalmente conectada, cada neurônio da primeira camada oculta precisa de uma conexão com cada um desses 120.000 pixels.

\begin{observacao}{Cálculo de Parâmetros}{param_explosion}
Para uma única camada totalmente conectada processando uma imagem 200×200 RGB para outra representação do mesmo tamanho:
\[
\text{Parâmetros} = (200 \times 200 \times 3)^2 = 14.400.000.000 \text{ pesos}
\]
Isso é 14,4 bilhões de parâmetros para \textbf{apenas uma camada}!
\end{observacao}

Esse número astronômico de parâmetros traz várias consequências negativas:
\begin{itemize}
    \item \textbf{Requisitos computacionais}: Memória e processamento tornam-se proibitivos
    \item \textbf{Overfitting}: Com tantos parâmetros, o modelo pode facilmente memorizar os dados de treino
    \item \textbf{Necessidade de dados}: Seriam necessários conjuntos de dados enormes para treinar adequadamente
    \item \textbf{Tempo de treinamento}: A convergência seria extremamente lenta
\end{itemize}

\subsection{Perda de Estrutura Espacial}

\begin{definicao}{Achatamento de Dados}{flattening}
MLPs requerem que imagens 2D (ou 3D com canais de cor) sejam "achatadas" em vetores 1D. Esse processo destrói completamente a topologia espacial da imagem:
\[
\text{Imagem}_{H \times W \times C} \rightarrow \text{Vetor}_{H \cdot W \cdot C \times 1}
\]
onde H é altura, W é largura, e C é o número de canais.
\end{definicao}

Quando achatamos uma imagem, pixels que eram vizinhos podem ficar distantes no vetor resultante. Por exemplo, dois pixels adjacentes horizontalmente estarão separados por W posições no vetor achatado. Isso significa que a MLP precisa aprender essas relações espaciais do zero, sem nenhuma estrutura inerente que facilite esse aprendizado.

\subsection{Ausência de Invariância à Translação}

Um dos problemas mais críticos das MLPs para visão é a falta de \highlight{invariância à translação}. Se treinamos uma MLP para reconhecer um gato no canto superior esquerdo de uma imagem, ela não necessariamente reconhecerá o mesmo gato se ele aparecer no canto inferior direito.

\begin{teorema}{Invariância à Translação}{translation_invariance}
Uma função $f$ é invariante à translação se:
\[
f(T_{\delta}(x)) = f(x)
\]
onde $T_{\delta}$ é um operador de translação por $\delta$ pixels. MLPs não possuem essa propriedade naturalmente, enquanto CNNs a incorporam através do compartilhamento de pesos.
\end{teorema}

\section{A Natureza Hierárquica da Visão}

\subsection{Como o Cérebro Processa Informação Visual}

O sistema visual humano processa informações de forma hierárquica, uma descoberta fundamental de Hubel e Wiesel que lhes rendeu o Prêmio Nobel. Neurônios no córtex visual primário (V1) respondem a características simples como bordas em orientações específicas. Áreas superiores combinam essas características simples em representações cada vez mais complexas.

\begin{observacao}{Hierarquia Visual Biológica}{bio_hierarchy}
O processamento visual no cérebro segue uma hierarquia clara:
\begin{enumerate}
    \item \textbf{V1}: Detectores de bordas e orientação
    \item \textbf{V2}: Formas simples e texturas
    \item \textbf{V4}: Formas intermediárias e cores
    \item \textbf{IT (Córtex Inferotemporal)}: Objetos completos e faces
\end{enumerate}
\end{observacao}

\subsection{Construção de Representações Complexas}

As CNNs imitam essa hierarquia natural. Consideremos como uma CNN pode aprender a reconhecer um gato:

\begin{exemplo}{Hierarquia de Features para Reconhecimento de Gato}{cat_features}
\begin{enumerate}
    \item \textbf{Primeira camada}: Aprende detectores de bordas em várias orientações
    \item \textbf{Segunda camada}: Combina bordas para formar círculos e curvas
    \item \textbf{Terceira camada}: Combina círculos para formar olhos; curvas para formar orelhas
    \item \textbf{Camadas posteriores}: Combina olhos, orelhas e textura de pelo para reconhecer face de gato
    \item \textbf{Camada final}: Integra todas as características para classificação
\end{enumerate}
\end{exemplo}

Essa abordagem hierárquica é fundamental porque permite que a rede reutilize características aprendidas. Um detector de bordas aprendido pode ser útil para reconhecer não apenas gatos, mas também cachorros, carros, ou qualquer outro objeto.

\section{Convolução: O Coração das CNNs}

\subsection{Operação de Convolução}

A operação de convolução é o elemento fundamental que dá nome às CNNs. Em vez de conectar cada neurônio a todos os pixels da imagem, a convolução usa um pequeno filtro (ou kernel) que "desliza" sobre a imagem.

\begin{definicao}{Convolução Discreta 2D}{conv2d}
Dados uma imagem $I$ e um kernel $K$ de tamanho $m \times n$, a convolução é definida como:
\[
(I * K)(i,j) = \sum_{p=0}^{m-1} \sum_{q=0}^{n-1} I(i+p, j+q) \cdot K(p,q)
\]
onde $(i,j)$ é a posição na imagem de saída.
\end{definicao}

A convolução tem várias propriedades importantes que a tornam ideal para processamento de imagens:
\begin{itemize}
    \item \textbf{Localidade}: Cada neurônio vê apenas uma pequena região da imagem
    \item \textbf{Compartilhamento de pesos}: O mesmo filtro é aplicado em toda a imagem
    \item \textbf{Equivariância à translação}: Se a entrada se move, a saída se move proporcionalmente
\end{itemize}

\subsection{Filtros como Detectores de Características}

Filtros convolucionais atuam como detectores de características locais. Diferentes configurações de pesos no filtro permitem detectar diferentes padrões:

\begin{exemplo}{Filtros Clássicos}{classic_filters}
\textbf{Detector de Bordas Verticais (Sobel):}
\[
K_{vertical} = \begin{bmatrix}
-1 & 0 & 1 \\
-2 & 0 & 2 \\
-1 & 0 & 1
\end{bmatrix}
\]

\textbf{Detector de Bordas Horizontais:}
\[
K_{horizontal} = \begin{bmatrix}
-1 & -2 & -1 \\
0 & 0 & 0 \\
1 & 2 & 1
\end{bmatrix}
\]

\textbf{Filtro de Nitidez (Sharpening):}
\[
K_{sharp} = \begin{bmatrix}
0 & -1 & 0 \\
-1 & 5 & -1 \\
0 & -1 & 0
\end{bmatrix}
\]
\end{exemplo}

Em CNNs, esses filtros não são definidos manualmente, mas \highlight{aprendidos através de backpropagation}. Isso permite que a rede descubra automaticamente quais características são mais úteis para a tarefa em questão.

\section{Arquitetura de uma CNN}

\subsection{Camadas Convolucionais}

As camadas convolucionais são o componente principal das CNNs. Cada camada convolucional contém múltiplos filtros, cada um produzindo um "mapa de características" (feature map) diferente.

\begin{definicao}{Camada Convolucional}{conv_layer}
Uma camada convolucional com $N$ filtros transforma uma entrada com $C_{in}$ canais em uma saída com $C_{out} = N$ canais:
\[
\text{Input}_{H \times W \times C_{in}} \xrightarrow{N \text{ filtros}} \text{Output}_{H' \times W' \times N}
\]
onde $H'$ e $W'$ dependem do padding e stride utilizados.
\end{definicao}

\subsubsection{Hiperparâmetros das Camadas Convolucionais}

\begin{observacao}{Hiperparâmetros Principais}{conv_hyperparams}
\begin{itemize}
    \item \textbf{Tamanho do filtro}: Geralmente 3×3, 5×5, ou 7×7. Filtros menores (3×3) são preferidos em redes modernas
    \item \textbf{Número de filtros}: Tipicamente aumenta em camadas mais profundas (32 → 64 → 128 → 256)
    \item \textbf{Stride}: Passo do filtro. Stride=1 mantém resolução espacial, stride=2 reduz pela metade
    \item \textbf{Padding}: Adiciona zeros nas bordas. "Same" padding preserva dimensões, "valid" padding as reduz
\end{itemize}
\end{observacao}

\subsection{Camadas de Pooling}

Pooling é uma operação de subamostragem que reduz a dimensionalidade espacial dos mapas de características, diminuindo o número de parâmetros e computação na rede.

\begin{definicao}{Max Pooling}{max_pool}
Max pooling com janela $k \times k$ e stride $s$ seleciona o valor máximo em cada região:
\[
y_{i,j} = \max_{p,q \in R_{i,j}} x_{p,q}
\]
onde $R_{i,j}$ é a região $k \times k$ começando na posição $(i \cdot s, j \cdot s)$.
\end{definicao}

\begin{teorema}{Efeito do Pooling na Dimensionalidade}{pooling_dim}
Para uma entrada de tamanho $H \times W$, pooling com janela $k \times k$ e stride $s$ produz saída de tamanho:
\[
H_{out} = \left\lfloor \frac{H - k}{s} \right\rfloor + 1, \quad W_{out} = \left\lfloor \frac{W - k}{s} \right\rfloor + 1
\]
Max pooling 2×2 com stride 2 reduz cada dimensão espacial pela metade.
\end{teorema}

\subsubsection{Motivação para Pooling}

O pooling serve múltiplos propósitos:
\begin{enumerate}
    \item \textbf{Redução de parâmetros}: Diminui o tamanho dos feature maps
    \item \textbf{Invariância local}: Pequenas translações na entrada não afetam a saída
    \item \textbf{Campo receptivo maior}: Neurônios em camadas posteriores "veem" regiões maiores da imagem original
    \item \textbf{Controle de overfitting}: Menos parâmetros significa menor capacidade de memorização
\end{enumerate}

\subsection{Arquitetura Típica}

Uma CNN típica segue um padrão de camadas que alternam entre convolução e pooling, seguidas por camadas totalmente conectadas no final:

\begin{algoritmo}{Arquitetura CNN Padrão}{standard_cnn}
\begin{enumerate}
    \item \textbf{Bloco 1}: Conv → ReLU → Conv → ReLU → MaxPool
    \item \textbf{Bloco 2}: Conv → ReLU → Conv → ReLU → MaxPool
    \item \textbf{Bloco 3}: Conv → ReLU → Conv → ReLU → MaxPool
    \item \textbf{Flatten}: Achata o tensor 3D em vetor 1D
    \item \textbf{Classificador}: FC → ReLU → FC → ReLU → FC → Softmax
\end{enumerate}
\end{algoritmo}

\section{Comparação Detalhada: CNN vs MLP}

\subsection{Análise de Parâmetros}

A diferença no número de parâmetros entre CNNs e MLPs é dramática. Vamos comparar duas arquiteturas para processar imagens 32×32 em escala de cinza:

\begin{exemplo}{Comparação de Parâmetros}{param_comparison}
\textbf{MLP com uma camada oculta de 100 neurônios:}
\begin{itemize}
    \item Entrada para oculta: $32 \times 32 \times 100 = 102.400$ parâmetros
    \item Oculta para saída (10 classes): $100 \times 10 = 1.000$ parâmetros
    \item Total: 103.400 parâmetros
\end{itemize}

\textbf{CNN simples:}
\begin{itemize}
    \item Conv1 (32 filtros 3×3): $3 \times 3 \times 1 \times 32 = 288$ parâmetros
    \item Conv2 (64 filtros 3×3): $3 \times 3 \times 32 \times 64 = 18.432$ parâmetros
    \item FC (após pooling para 7×7×64): $7 \times 7 \times 64 \times 10 = 31.360$ parâmetros
    \item Total: ~50.000 parâmetros
\end{itemize}

A CNN tem \textbf{metade dos parâmetros} mas geralmente alcança melhor performance!
\end{exemplo}

\subsection{Propriedades Comparativas}

\begin{observacao}{Vantagens das CNNs sobre MLPs}{cnn_advantages}
\begin{enumerate}
    \item \textbf{Eficiência de parâmetros}: CNNs usam compartilhamento de pesos
    \item \textbf{Preservação de estrutura}: Mantém relações espaciais
    \item \textbf{Invariância à translação}: Built-in através de convoluções
    \item \textbf{Composicionalidade}: Hierarquia natural de características
    \item \textbf{Generalização}: Melhor performance com menos dados
\end{enumerate}
\end{observacao}

\section{Implementação Prática}

\subsection{Exemplo em TensorFlow/Keras}

Vamos implementar uma CNN simples para o dataset MNIST, demonstrando os conceitos discutidos:

\begin{minted}[bgcolor=gray!10, fontsize=\footnotesize]{python}
import tensorflow as tf
from tensorflow.keras import layers, models

def criar_cnn_mnist():
    """
    Cria uma CNN simples para classificação de dígitos MNIST.
    Arquitetura: Conv->Pool->Conv->Pool->FC->Output
    """
    model = models.Sequential([
        # Primeira camada convolucional
        layers.Conv2D(32, (3, 3), activation='relu', 
                     input_shape=(28, 28, 1)),
        layers.MaxPooling2D((2, 2)),
        
        # Segunda camada convolucional
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        # Terceira camada convolucional
        layers.Conv2D(64, (3, 3), activation='relu'),
        
        # Flatten e camadas densas
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(10, activation='softmax')
    ])
    
    return model

# Compilar modelo
model = criar_cnn_mnist()
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Visualizar arquitetura
model.summary()
\end{minted}

\subsection{Análise da Arquitetura}

Vamos analisar como as dimensões mudam através da rede:

\begin{observacao}{Fluxo de Dimensões}{dimension_flow}
Para entrada MNIST (28×28×1):
\begin{enumerate}
    \item Input: 28×28×1
    \item Após Conv2D(32, 3×3): 26×26×32 (sem padding)
    \item Após MaxPool(2×2): 13×13×32
    \item Após Conv2D(64, 3×3): 11×11×64
    \item Após MaxPool(2×2): 5×5×64
    \item Após Conv2D(64, 3×3): 3×3×64
    \item Após Flatten: 576
    \item Após Dense(64): 64
    \item Output: 10
\end{enumerate}
Total de parâmetros: ~100k (compare com ~800k para MLP equivalente)
\end{observacao}

\section{Técnicas Avançadas e Boas Práticas}

\subsection{Data Augmentation}

Data augmentation é crucial para melhorar a generalização de CNNs, especialmente com datasets limitados:

\begin{algoritmo}{Pipeline de Data Augmentation}{data_aug}
\begin{minted}[bgcolor=gray!10, fontsize=\footnotesize]{python}
data_augmentation = tf.keras.Sequential([
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
    layers.RandomFlip("horizontal"),
    layers.RandomTranslation(0.1, 0.1),
    layers.RandomContrast(0.1)
])
\end{minted}
\end{algoritmo}

\subsection{Transfer Learning}

Transfer learning permite aproveitar redes pré-treinadas em grandes datasets:

\begin{observacao}{Estratégias de Transfer Learning}{transfer_strategies}
\begin{enumerate}
    \item \textbf{Feature Extraction}: Congela camadas convolucionais, treina apenas classificador
    \item \textbf{Fine-tuning}: Descongela últimas camadas convolucionais para ajuste fino
    \item \textbf{Inicialização}: Usa pesos pré-treinados como ponto de partida
\end{enumerate}
\end{observacao}

\subsection{Batch Normalization}

Batch normalization acelera o treinamento e melhora a estabilidade:

\begin{definicao}{Batch Normalization}{batch_norm}
Para cada mini-batch, normaliza as ativações:
\[
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
\]
\[
y_i = \gamma \hat{x}_i + \beta
\]
onde $\mu_B$ e $\sigma_B^2$ são média e variância do batch, $\gamma$ e $\beta$ são parâmetros aprendidos.
\end{definicao}

\section{Aplicações e Arquiteturas Famosas}

\subsection{Evolução das Arquiteturas}

A evolução das CNNs pode ser traçada através de arquiteturas marcos:

\begin{observacao}{Arquiteturas Históricas}{historical_archs}
\begin{itemize}
    \item \textbf{LeNet-5 (1998)}: Pioneira, 7 camadas, ~60k parâmetros
    \item \textbf{AlexNet (2012)}: Vencedora ImageNet, 8 camadas, 60M parâmetros
    \item \textbf{VGGNet (2014)}: Filtros 3×3 uniformes, 16-19 camadas, 138M parâmetros
    \item \textbf{GoogLeNet (2014)}: Módulos Inception, 22 camadas, 5M parâmetros
    \item \textbf{ResNet (2015)}: Conexões residuais, 152+ camadas, 60M parâmetros
    \item \textbf{EfficientNet (2019)}: Otimização de arquitetura, escalável
\end{itemize}
\end{observacao}

\subsection{Aplicações Modernas}

As CNNs revolucionaram múltiplas áreas:

\begin{exemplo}{Aplicações de CNNs}{cnn_applications}
\textbf{Visão Computacional:}
\begin{itemize}
    \item Classificação de imagens (ImageNet, CIFAR)
    \item Detecção de objetos (YOLO, Faster R-CNN)
    \item Segmentação semântica (U-Net, DeepLab)
    \item Reconhecimento facial (FaceNet, DeepFace)
\end{itemize}

\textbf{Medicina:}
\begin{itemize}
    \item Diagnóstico de câncer em imagens médicas
    \item Análise de retina para detecção de doenças
    \item Segmentação de órgãos em tomografias
\end{itemize}

\textbf{Indústria:}
\begin{itemize}
    \item Inspeção de qualidade automatizada
    \item Veículos autônomos
    \item Agricultura de precisão
\end{itemize}
\end{exemplo}

\section{Desafios e Limitações}

\subsection{Limitações das CNNs}

Apesar do sucesso, CNNs têm limitações importantes:

\begin{observacao}{Limitações Conhecidas}{cnn_limitations}
\begin{enumerate}
    \item \textbf{Necessidade de dados}: Requerem grandes datasets para treinar do zero
    \item \textbf{Interpretabilidade}: Difícil entender o que a rede aprendeu
    \item \textbf{Sensibilidade a adversários}: Pequenas perturbações podem enganar a rede
    \item \textbf{Falta de entendimento geométrico}: Não capturam relações parte-todo naturalmente
    \item \textbf{Custo computacional}: Treinamento e inferência podem ser caros
\end{enumerate}
\end{observacao}

\subsection{Direções Futuras}

Pesquisas atuais buscam superar essas limitações:

\begin{observacao}{Tendências de Pesquisa}{research_trends}
\begin{itemize}
    \item \textbf{Vision Transformers}: Aplicação de attention mechanisms para visão
    \item \textbf{Capsule Networks}: Melhor modelagem de hierarquias parte-todo
    \item \textbf{Neural Architecture Search}: Automação do design de arquiteturas
    \item \textbf{Efficient CNNs}: Modelos menores e mais rápidos para dispositivos móveis
    \item \textbf{Self-supervised learning}: Reduzir dependência de dados rotulados
\end{itemize}
\end{observacao}

\section{Conclusões}

As Redes Neurais Convolucionais representam uma especialização bem-sucedida das MLPs para o domínio visual. Ao incorporar conhecimento sobre a estrutura hierárquica e local das imagens através de convoluções e pooling, as CNNs conseguem alcançar performance superior com ordens de magnitude menos parâmetros.

Os princípios fundamentais das CNNs - localidade, compartilhamento de pesos, e hierarquia composicional - não são apenas truques de engenharia, mas refletem propriedades fundamentais do processamento visual biológico e da estrutura dos dados visuais.

\begin{observacao}{Resumo dos Conceitos Principais}{summary}
\begin{enumerate}
    \item CNNs são MLPs especializadas que exploram estrutura espacial
    \item Convolução permite detecção local de características com compartilhamento de pesos
    \item Pooling reduz dimensionalidade e adiciona invariância local
    \item Arquitetura hierárquica constrói representações complexas de simples
    \item Transfer learning e data augmentation são essenciais na prática
    \item CNNs revolucionaram visão computacional mas têm limitações conhecidas
\end{enumerate}
\end{observacao}

O sucesso das CNNs em visão computacional inspirou aplicações em outros domínios com estrutura local, incluindo processamento de áudio (espectrogramas), processamento de texto (CNNs 1D), e até mesmo grafos (Graph CNNs). O princípio de explorar estrutura conhecida nos dados através de arquiteturas especializadas continua sendo uma das ideias mais poderosas em deep learning.

\end{document}