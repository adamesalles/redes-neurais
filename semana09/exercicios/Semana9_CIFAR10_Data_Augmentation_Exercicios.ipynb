{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando CIFAR-10 com Data Augmentation\n",
    "\n",
    "Neste exercício, revisitamos o CIFAR-10 e as redes que construímos anteriormente. Usaremos data augmentation (aumento de dados) em tempo real para tentar melhorar nossos resultados.\n",
    "\n",
    "Quando terminar de passar pelo notebook, experimente diferentes parâmetros de data augmentation e veja se eles ajudam (ou prejudicam!) o desempenho do seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados, embaralhados e divididos entre conjuntos de treino e teste:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('Formato de x_train:', x_train.shape)\n",
    "print(x_train.shape[0], 'amostras de treino')\n",
    "print(x_test.shape[0], 'amostras de teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Exercício 6, construímos dois modelos. Um era menor (181K parâmetros) enquanto o segundo era maior (1.25M parâmetros). Abaixo, usamos o modelo menor e o treinamos com data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos construir uma CNN usando as capacidades Sequential do Keras\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "## Convolução 5x5 com stride 2x2 e 32 filtros\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Outra convolução 5x5 com stride 2x2 e 32 filtros\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Max pooling 2x2 reduz para 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten transforma 3x3x32 em 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda temos 181K parâmetros, mesmo que este seja um modelo \"pequeno\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Inicializar otimizador RMSprop\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005, decay=1e-6)\n",
    "\n",
    "# Vamos treinar o modelo usando RMSprop\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui definimos o `ImageDataGenerator` que usaremos para servir imagens ao nosso modelo durante o processo de treinamento. Atualmente, ele está configurado para fazer alguns deslocamentos e inversão horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # definir média de entrada para 0 sobre o conjunto de dados\n",
    "    samplewise_center=False,  # definir cada média de amostra para 0\n",
    "    featurewise_std_normalization=False,  # dividir entradas pelo desvio padrão do conjunto de dados\n",
    "    samplewise_std_normalization=False,  # dividir cada entrada pelo seu desvio padrão\n",
    "    zca_whitening=False,  # aplicar whitening ZCA\n",
    "    rotation_range=0,  # girar aleatoriamente imagens no intervalo (graus, 0 a 180)\n",
    "    width_shift_range=0.1,  # deslocar aleatoriamente imagens horizontalmente (fração da largura total)\n",
    "    height_shift_range=0.1,  # deslocar aleatoriamente imagens verticalmente (fração da altura total)\n",
    "    horizontal_flip=True,  # inverter aleatoriamente imagens horizontalmente\n",
    "    vertical_flip=False)  # inverter aleatoriamente imagens verticalmente\n",
    "                   \n",
    "datagen.fit(x_train)      # Isso calcula quaisquer estatísticas que possam ser necessárias (por exemplo, para centralização) a partir do conjunto de treinamento.\n",
    "\n",
    "    \n",
    "# Ajustar o modelo nos lotes gerados por datagen.flow().\n",
    "model_1.fit(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=15,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o desempenho se compara com o treinamento sem augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "### Sua Vez\n",
    "\n",
    "1. Experimente acima com diferentes configurações dos parâmetros de data augmentation. Você consegue fazer o modelo ter um desempenho melhor? Você consegue fazer ele ter um desempenho pior?\n",
    "\n",
    "2. Como no Exercício 6, construa um modelo mais complicado com o seguinte padrão:\n",
    "    - Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Classificação Final\n",
    "    - Use strides de 1 para todas as camadas convolucionais.\n",
    "\n",
    "3. Use data augmentation para treinar este modelo. Você consegue obter um desempenho melhor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos construir uma CNN usando as capacidades Sequential do Keras\n",
    "\n",
    "# Por favor, forneça seu código aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verificar número de parâmetros (imprimir o summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar otimizador RMSprop\n",
    "\n",
    "# Vamos treinar o modelo usando RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular quantidades necessárias para normalização por feature\n",
    "\n",
    "\n",
    "# Ajustar o modelo nos lotes gerados por datagen.flow()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
