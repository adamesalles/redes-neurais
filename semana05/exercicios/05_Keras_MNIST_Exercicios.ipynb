{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção de Imagens Manuscritas com Keras usando dados MNIST\n",
    "\n",
    "Neste exercício trabalharemos com dados de imagem: especificamente o famoso conjunto de dados MNIST. Este conjunto de dados contém 70.000 imagens de dígitos manuscritos em tons de cinza (0=preto, 255 = branco). As imagens são de 28 pixels por 28 pixels para um total de 784 pixels. Isso é bem pequeno pelos padrões de imagem. Além disso, as imagens são bem centralizadas e isoladas. Isso torna este problema solucionável com redes neurais totalmente conectadas padrão sem muito pré-processamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na primeira parte deste notebook, vamos orientá-lo no carregamento dos dados, construção de uma rede e seu treinamento. Então será sua vez de experimentar diferentes modelos e ver se consegue melhorar o desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminares\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Compatibilidade Python 2/3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar objetos do Keras para Deep Learning\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos explorar um pouco o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados, embaralhados e divididos entre conjuntos de treino e teste (x_train e y_train)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos apenas observar um exemplo específico para ver o que há dentro\n",
    "\n",
    "x_train[333]  ## Apenas um array numpy 28 x 28 de inteiros de 0 a 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qual é o rótulo correspondente no conjunto de treinamento?\n",
    "y_train[333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos ver como essa imagem realmente se parece\n",
    "\n",
    "plt.imshow(x_train[333], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esta é a forma do np.array x_train\n",
    "# é tridimensional.\n",
    "print(x_train.shape, 'amostras de treino')\n",
    "print(x_test.shape, 'amostras de teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para nossos propósitos, essas imagens são apenas um vetor de 784 entradas, então vamos converter\n",
    "x_train = x_train.reshape(len(x_train), 28*28)\n",
    "x_test = x_test.reshape(len(x_test), 28*28)\n",
    "\n",
    "## Keras funciona com floats, então devemos converter os números para floats\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "## Normalizar as entradas para que estejam entre 0 e 1\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter vetores de classe em matrizes de classe binárias\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train[333]  # agora o dígito k é representado por um 1 na k-ésima entrada (indexada em 0) do vetor de comprimento 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construiremos um modelo com duas camadas ocultas de tamanho 512\n",
    "# Entradas totalmente conectadas em cada camada\n",
    "# Usaremos dropout de 0.2 para ajudar na regularização\n",
    "model_1 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(784,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note que este modelo tem MUITOS parâmetros\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos compilar o modelo\n",
    "learning_rate = .001\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "# note que `categorical cross entropy` é a generalização natural \n",
    "# da função de perda que tínhamos no caso de classificação binária, para o caso multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E agora vamos treinar.\n",
    "\n",
    "batch_size = 128  # mini-batch com 128 exemplos\n",
    "epochs = 30\n",
    "history = model_1.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Usaremos a função evaluate do Keras para avaliar o desempenho no conjunto de teste\n",
    "\n",
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Perda no teste:', score[0])\n",
    "print('Precisão no teste:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Perda de Treino\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Perda de Validação\")\n",
    "    ax.legend()\n",
    "    ax.set_title('perda cross_entropy')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[\"accuracy\"],'r-x', label=\"Precisão de Treino\")\n",
    "    ax.plot(history.history[\"val_accuracy\"],'b-x', label=\"Precisão de Validação\")\n",
    "    ax.legend()\n",
    "    ax.set_title('precisão')\n",
    "    ax.grid(True)\n",
    "    \n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este é um desempenho razoavelmente bom, mas podemos fazer ainda melhor! A seguir, você construirá uma rede ainda maior e comparará o desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "### Sua vez: Construa seu próprio modelo\n",
    "Use a funcionalidade \"Sequential\" do Keras para construir `model_2` com as seguintes especificações:\n",
    "\n",
    "1. Duas camadas ocultas.\n",
    "2. Primeira camada oculta de tamanho 400 e segunda de tamanho 300\n",
    "3. Dropout de 0.4 em cada camada\n",
    "4. Quantos parâmetros seu modelo tem? Como ele se compara com o modelo anterior?\n",
    "4. Treine este modelo por 20 épocas com RMSProp a uma taxa de aprendizado de 0.001 e tamanho de lote de 128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construa seu modelo aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pense sobre as seguintes questões\n",
    "\n",
    "1) Como model_1 e model_2 se comparam? Qual você prefere? Se você fosse colocar um em produção, qual escolheria e por quê?\n",
    "\n",
    "2) Compare as trajetórias da função de perda no conjunto de treinamento e no conjunto de teste para cada modelo? Como elas se comparam? O que isso sugere sobre cada modelo? Faça o mesmo para a precisão? Qual você acha mais significativo, a perda ou a precisão?\n",
    "\n",
    "3) Sugira uma melhoria para um dos modelos (mudança de estrutura, taxa de aprendizado, número de épocas, etc.) que você acha que resultará em um modelo melhor. Teste abaixo? Isso melhorou o desempenho?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
