{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando Modelos Pré-Treinados\n",
    "Neste exercício vamos mostrar como carregar modelos pré-treinados como VGG16 e ResNet. Este é um exercício bastante simples projetado para familiarizá-lo com modelos como VGG e ResNet e a saída que eles fornecem.\n",
    "\n",
    "Você vai carregar os modelos VGG e ResNet. Em seguida, você usará a câmera do seu laptop para tirar uma foto. Então você vai executar sua foto através desses modelos para ver os resultados.\n",
    "\n",
    "Você também pode tirar fotos você mesmo e enviá-las manualmente. Ou encontrar imagens na internet e baixá-las.\n",
    "\n",
    "Observe os resultados de pelo menos 5 fotos diferentes e considere:\n",
    "\n",
    "- Os modelos acertaram a resposta \"correta\"? A resposta \"correta\" estava na lista?\n",
    "- Quão confiante foi a previsão (a escolha principal teve uma probabilidade próxima de 1?)\n",
    "- Como o modelo lidou com fotos com múltiplos objetos nelas? (por exemplo, a foto da cadeira de balanço)\n",
    "- Quais foram algumas das respostas \"erradas\" na lista? Você consegue entender por que o classificador de imagens pode ter pensado que essas outras respostas estavam corretas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instale opencv se você ainda não tiver\n",
    "# conda install -c https://conda.binstar.org/menpo opencv3\n",
    "# pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminares\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Compatibilidade Python 2/3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(camera):\n",
    "    retval, im = camera.read()\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_webcam_image(img_path):\n",
    "\n",
    "    try:\n",
    "        camera_port = 0\n",
    "        ramp_frames = 10\n",
    "    \n",
    "        camera = cv2.VideoCapture(camera_port)\n",
    "\n",
    "        for i in range(ramp_frames):\n",
    "            retval, im_camera = camera.read()\n",
    "\n",
    "        retval, im_camera = camera.read()\n",
    "\n",
    "        im = cv2.resize(im_camera, (224, 224)).astype(np.float32)\n",
    "        cv2.imwrite(img_path, im)\n",
    "        del (camera)\n",
    "        return True\n",
    "    except ValueError as e:\n",
    "        print(\"Falha na Captura de Imagem\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"webcam_test_img.png\"\n",
    "\n",
    "if save_webcam_image(img_path) is False:\n",
    "    # Webcam não ativa, use a imagem da cadeira de balanço\n",
    "    img_path = \"rocking_chair.jpg\"\n",
    "    print(\"Usando a Imagem de Teste da Cadeira de Balanço: {}\".format(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e exibir a imagem usando matplotlib\n",
    "img = plt.imread(img_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 - Modelo Pré-Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importar objetos do Keras para Deep Learning\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "vgg16_model = vgg16.VGG16(weights='imagenet')\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função Utilitária para Carregar Imagem, Pré-processar Entrada e Alvos\n",
    "def predict_image(model, img_path, preprocess_input_fn, decode_predictions_fn, target_size=(224, 224)):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input_fn(x)\n",
    "    \n",
    "    preds = model.predict(x)\n",
    "    predictions_df = pd.DataFrame(decode_predictions_fn(preds, top=10)[0])\n",
    "    predictions_df.columns = [\"Classe Prevista\", \"Nome\", \"Probabilidade\"]\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path=\"rocking_chair.png\"  ## Descomente isso e coloque o caminho para seu arquivo aqui se desejar\n",
    "# Prever Resultados\n",
    "predict_image(vgg16_model, img_path, vgg16.preprocess_input, vgg16.decode_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50 - Modelo Pré-Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina um modelo Resnet e imprima o resumo do modelo (siga o mesmo procedimento do VGGNet)\n",
    "\n",
    "# Ele fará o download dos pesos, o que pode demorar um pouco\n",
    "# Além disso, o resumo será bem longo, já que Resnet50 é uma rede muito maior que VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prever Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
