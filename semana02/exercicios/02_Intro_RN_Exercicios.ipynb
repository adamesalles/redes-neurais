{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução às Redes Neurais\n",
    "\n",
    "## Exercício: neurônios como portas lógicas\n",
    "Neste exercício vamos experimentar com computações de neurônios. Mostraremos como representar funções lógicas básicas como AND, OR e XOR usando neurônios únicos (ou estruturas mais complicadas). Finalmente, ao final vamos percorrer como representar redes neurais como uma sequência de computações matriciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função sigmoid:\n",
    "\n",
    "$$\n",
    "\\sigma = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "$\\sigma$ varia de (0, 1). Quando a entrada $x$ é negativa, $\\sigma$ está próximo de 0. Quando $x$ é positivo, $\\sigma$ está próximo de 1. Em $x=0$, $\\sigma=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definir rapidamente a função sigmoid\n",
    "def sigmoid(x):\n",
    "    \"\"\"Função sigmoid\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a função sigmoid\n",
    "vals = np.linspace(-10, 10, num=100, dtype=np.float32)\n",
    "activation = sigmoid(vals)\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.plot(vals, activation)\n",
    "plt.grid(True, which='both')\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.axvline(x=0, color='k')\n",
    "plt.yticks()\n",
    "plt.ylim([-0.5, 1.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensando em neurônios como portas lógicas booleanas\n",
    "\n",
    "Uma porta lógica recebe duas entradas booleanas (verdadeiro/falso ou 1/0), e retorna 0 ou 1 dependendo de sua regra. A tabela verdade para uma porta lógica mostra as saídas para cada combinação de entradas, (0, 0), (0, 1), (1,0) e (1, 1). Por exemplo, vamos ver a tabela verdade para uma porta \"OR\":\n",
    "\n",
    "### Porta OR\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">Tabela verdade da porta OR</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Entrada</th>\n",
    "<th>Saída</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Um neurônio que usa a função de ativação sigmoid produz um valor entre (0, 1). Isso naturalmente nos leva a pensar sobre valores booleanos. Imagine um neurônio que recebe duas entradas, $x_1$ e $x_2$, e um termo de viés:\n",
    "\n",
    "![](images/logic01.png)\n",
    "\n",
    "Ao limitar as entradas de $x_1$ e $x_2$ para estar em $\\left\\{0, 1\\right\\}$, podemos simular o efeito de portas lógicas com nosso neurônio. O objetivo é encontrar os pesos (representados pelas marcas ? acima), de tal forma que retorne uma saída próxima de 0 ou 1 dependendo das entradas.\n",
    "\n",
    "Que números para os pesos precisaríamos preencher para que esta porta produza lógica OR? Lembre-se: $\\sigma(z)$ está próximo de 0 quando $z$ é amplamente negativo (cerca de -10 ou menos), e está próximo de 1 quando $z$ é amplamente positivo (cerca de +10 ou maior).\n",
    "\n",
    "$$\n",
    "z = w_1 x_1 + w_2 x_2 + b\n",
    "$$\n",
    "\n",
    "Vamos pensar sobre isso:\n",
    "\n",
    "* Quando $x_1$ e $x_2$ são ambos 0, o único valor afetando $z$ é $b$. Como queremos que o resultado para (0, 0) seja próximo de zero, $b$ deve ser negativo (pelo menos -10)\n",
    "* Se $x_1$ ou $x_2$ for 1, queremos que a saída seja próxima de 1. Isso significa que os pesos associados com $x_1$ e $x_2$ devem ser suficientes para compensar $b$ ao ponto de causar $z$ ser pelo menos 10.\n",
    "* Vamos dar a $b$ um valor de -10. Quão grandes precisam ser $w_1$ e $w_2$? \n",
    "    * Pelo menos +20\n",
    "* Então vamos tentar $w_1=20$, $w_2=20$ e $b=-10$!\n",
    "\n",
    "![](images/logic02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logic_gate(w1, w2, b):\n",
    "    # Auxiliar para criar funções de porta lógica\n",
    "    # Conecte valores para peso_a, peso_b e viés\n",
    "    return lambda x1, x2: sigmoid(w1 * x1 + w2 * x2 + b)\n",
    "\n",
    "def test(gate):\n",
    "    # Função auxiliar para testar nossas funções de peso.\n",
    "    for a, b in (0, 0), (0, 1), (1, 0), (1, 1):\n",
    "        print(\"{}, {}: {}\".format(a, b, np.round(gate(a, b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "or_gate = logic_gate(20, 20, -10)\n",
    "test(or_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">Tabela verdade da porta OR</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Entrada</th>\n",
    "<th>Saída</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Isso combina! Ótimo! Agora você tenta encontrar os valores de peso apropriados para cada tabela verdade. Tente não adivinhar e verificar - pense logicamente e tente derivar valores que funcionem.\n",
    "\n",
    "### Porta AND\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">Tabela verdade da porta AND</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Entrada</th>\n",
    "<th>Saída</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "Tente descobrir que valores para os neurônios fariam esta função como uma porta AND."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA FAZER: Preencha os parâmetros w1, w2 e b de tal forma que a tabela verdade corresponda\n",
    "and_gate = logic_gate(0,0,0)\n",
    "\n",
    "test(and_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "Faça o mesmo para a porta NOR e a porta NAND."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porta NOR (Não Ou)\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">Tabela verdade da porta NOR</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Entrada</th>\n",
    "<th>Saída</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA FAZER: Preencha os parâmetros w1, w2 e b de tal forma que a tabela verdade corresponda\n",
    "nor_gate = logic_gate(0, 0, 0)\n",
    "\n",
    "test(nor_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porta NAND (Não E)\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">Tabela verdade da porta NAND</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Entrada</th>\n",
    "<th>Saída</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA FAZER: Preencha os parâmetros w1, w2 e b de tal forma que a tabela verdade corresponda\n",
    "nand_gate = logic_gate(0, 0, 0)\n",
    "\n",
    "test(nand_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Os limites de neurônios únicos\n",
    "\n",
    "Se você fez cursos de ciência da computação, pode saber que as portas XOR são a base da computação. Elas podem ser usadas como chamados \"meio-somadores\", a fundação de ser capaz de somar números juntos. Aqui está a tabela verdade para XOR:\n",
    "\n",
    "### Porta XOR (Ou Exclusivo)\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"3\">Tabela verdade da porta XOR</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<th colspan=\"2\">Entrada</th>\n",
    "<th>Saída</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Agora a pergunta é, você pode criar um conjunto de pesos tal que um único neurônio possa produzir esta propriedade?\n",
    "\n",
    "Acontece que você não pode. Neurônios únicos não podem correlacionar entradas, então ficam apenas confusos. Então neurônios individuais estão fora. Ainda podemos usar neurônios para de alguma forma formar uma porta XOR?\n",
    "\n",
    "E se tentássemos algo mais complexo:\n",
    "\n",
    "![](images/logic03.png)\n",
    "\n",
    "Aqui, temos as entradas indo para duas portas separadas: o neurônio superior é uma porta OR, e o inferior é uma porta NAND. A saída dessas portas então é passada para outro neurônio, que é uma porta AND. Se você calcular as saídas em cada combinação de valores de entrada, verá que esta é uma porta XOR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certifique-se de que você tem or_gate, nand_gate e and_gate funcionando do exercício acima!\n",
    "\n",
    "def xor_gate(a, b):\n",
    "    c = or_gate(a, b)\n",
    "    d = nand_gate(a, b)\n",
    "    return and_gate(c, d)\n",
    "test(xor_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Feedforward como Computações Matriciais\n",
    "\n",
    "Discutimos anteriormente como a computação feed-forward de uma rede neural pode ser pensada como cálculos matriciais e funções de ativação. Faremos algumas computações reais com matrizes para ver isso em ação.\n",
    "\n",
    "![](images/FF_NN.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "Fornecidos abaixo estão os seguintes:\n",
    "\n",
    "- Três matrizes de peso `W_1`, `W_2` e `W_3` representando os pesos em cada camada. A convenção para essas matrizes é que cada $W_{i,j}$ dá o peso do neurônio $i$ na camada anterior (esquerda) para o neurônio $j$ na próxima camada (direita).\n",
    "- Um vetor `x_in` representando uma única entrada e uma matriz `x_mat_in` representando 7 entradas diferentes.\n",
    "- Duas funções: `soft_max_vec` e `soft_max_mat` que aplicam a função soft_max a um único vetor, e linha por linha a uma matriz.\n",
    "\n",
    "Os objetivos para este exercício são:\n",
    "1. Para a entrada `x_in` calcular as entradas e saídas para cada camada (assumindo ativações sigmoid para as duas camadas do meio e saída soft_max para a camada final).\n",
    "2. Escrever uma função que faça todo o cálculo da rede neural para uma única entrada\n",
    "3. Escrever uma função que faça todo o cálculo da rede neural para uma matriz de entradas, onde cada linha é uma única entrada.\n",
    "4. Testar suas funções em `x_in` e `x_mat_in`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = np.array([[2,-1,1,4],[-1,2,-3,1],[3,-2,-1,5]])\n",
    "W_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_2 = np.array([[3,1,-2,1],[-2,4,1,-4],[-1,-3,2,-5],[3,1,1,1]])\n",
    "W_3 = np.array([[-1,3,-2],[1,-1,-3],[3,-2,2],[1,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = np.array([.5,.8,.2])\n",
    "x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat_in = np.array([[.5,.8,.2],[.1,.9,.6],[.2,.2,.3],[.6,.1,.9],[.5,.5,.4],[.9,.1,.9],[.1,.8,.7]])\n",
    "x_mat_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max_vec(vec):\n",
    "    return np.exp(vec)/(np.sum(np.exp(vec)))\n",
    "\n",
    "def soft_max_mat(mat):\n",
    "    return np.exp(mat)/(np.sum(np.exp(mat),axis=1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estudante deve fazer os cálculos abaixo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
